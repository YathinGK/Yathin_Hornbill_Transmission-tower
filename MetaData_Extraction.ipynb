{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bd8e0aa-a07e-4dcd-8178-74e471052553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "âœ… Metadata extraction and image organization successfully completed!\n",
      "ðŸ“„ Metadata saved to organized_images\\metadata.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS, GPSTAGS\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Paths\n",
    "INPUT_DIR = \"Input_Images\"  # Input Image Folder\n",
    "OUTPUT_DIR = \"organized_images\"  \n",
    "CATEGORY_DIR = os.path.join(OUTPUT_DIR, \"Classified_Images\")  \n",
    "DATE_DIR = os.path.join(OUTPUT_DIR, \"Date_Wise_Images\")  \n",
    "MODEL_PATH = \"Trained_Model/thermal_visible_classifier.h5\"  # Path to Trained Model\n",
    "METADATA_CSV = os.path.join(OUTPUT_DIR, \"metadata.csv\")  # CSV Output File\n",
    "\n",
    "# Ensure Output Folders Exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(CATEGORY_DIR, exist_ok=True)\n",
    "os.makedirs(DATE_DIR, exist_ok=True)\n",
    "\n",
    "# Load trained CNN model\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"âŒ Error: Model file '{MODEL_PATH}' not found! Train the model first.\")\n",
    "    exit()\n",
    "\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "# Function to extract metadata from an image\n",
    "def extract_metadata(image_path):\n",
    "    metadata = {\"FileName\": os.path.basename(image_path)}\n",
    "    \n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        exif_data = img._getexif()\n",
    "        \n",
    "        if exif_data:\n",
    "            for tag, value in exif_data.items():\n",
    "                tag_name = TAGS.get(tag, tag)\n",
    "                if tag_name == \"GPSInfo\":\n",
    "                    gps_data = {GPSTAGS.get(t, t): v for t, v in value.items()}\n",
    "                    \n",
    "                    # Extract full latitude & longitude\n",
    "                    lat, lon = extract_gps_coordinates(gps_data)\n",
    "                    metadata[\"Latitude\"] = lat\n",
    "                    metadata[\"Longitude\"] = lon\n",
    "                elif tag_name == \"DateTime\":\n",
    "                    date_part, time_part = format_datetime(value)\n",
    "                    metadata[\"Date\"] = date_part\n",
    "                    metadata[\"Time\"] = time_part\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting metadata from {image_path}: {e}\")\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "# Function to extract full GPS coordinates\n",
    "def extract_gps_coordinates(gps_data):\n",
    "    try:\n",
    "        lat_values = gps_data.get(\"GPSLatitude\", (0, 0, 0))\n",
    "        lon_values = gps_data.get(\"GPSLongitude\", (0, 0, 0))\n",
    "        \n",
    "        lat = lat_values[0] + (lat_values[1] / 60.0) + (lat_values[2] / 3600.0)\n",
    "        lon = lon_values[0] + (lon_values[1] / 60.0) + (lon_values[2] / 3600.0)\n",
    "\n",
    "        return f\"{lat:.10f}\", f\"{lon:.10f}\"  # Full-precision GPS values\n",
    "    except:\n",
    "        return \"Unknown\", \"Unknown\"\n",
    "\n",
    "# Function to format datetime\n",
    "def format_datetime(datetime_str):\n",
    "    try:\n",
    "        date_part, time_part = datetime_str.split(\" \")\n",
    "        formatted_date = date_part.replace(\":\", \"-\")  \n",
    "        return formatted_date, time_part\n",
    "    except:\n",
    "        return \"Unknown\", \"Unknown\"\n",
    "\n",
    "# Function to classify the image as Thermal or Visible\n",
    "def predict_image_category(image_path):\n",
    "    img_height, img_width = 224, 224  \n",
    "\n",
    "    img = image.load_img(image_path, target_size=(img_height, img_width))\n",
    "    img_array = image.img_to_array(img) / 255.0  \n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    prediction = model.predict(img_array)\n",
    "    return \"Visible\" if prediction[0][0] > 0.5 else \"Thermal\"\n",
    "\n",
    "# Function to process and organize images\n",
    "def organize_images():\n",
    "    metadata_list = []  # List to store metadata\n",
    "\n",
    "    for filename in os.listdir(INPUT_DIR):\n",
    "        file_path = os.path.join(INPUT_DIR, filename)\n",
    "        if not filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            continue  \n",
    "\n",
    "        metadata = extract_metadata(file_path)\n",
    "\n",
    "        # Extract metadata values\n",
    "        date = metadata.get(\"Date\", \"Unknown\")\n",
    "        time = metadata.get(\"Time\", \"Unknown\")\n",
    "        lat = metadata.get(\"Latitude\", \"Unknown\")\n",
    "        lon = metadata.get(\"Longitude\", \"Unknown\")\n",
    "\n",
    "        # Construct new filename using Date, Latitude, and Longitude\n",
    "        if date != \"Unknown\" and lat != \"Unknown\" and lon != \"Unknown\":\n",
    "            new_filename = f\"{date}_{lat}_{lon}.jpg\"\n",
    "        else:\n",
    "            new_filename = f\"unknown_{filename}\"\n",
    "\n",
    "        # Classify the image as Thermal or Visible\n",
    "        category = predict_image_category(file_path)\n",
    "\n",
    "        # Create category-based folders (Thermal & Visible)\n",
    "        category_folder = os.path.join(CATEGORY_DIR, category)\n",
    "        os.makedirs(category_folder, exist_ok=True)\n",
    "\n",
    "        # Create date-based folder inside Date_Wise_Images/\n",
    "        date_folder = os.path.join(DATE_DIR, date if date != \"Unknown\" else \"Unknown_Date\")\n",
    "        os.makedirs(date_folder, exist_ok=True)\n",
    "\n",
    "        # Move and rename file into both classified & date-based folders\n",
    "        category_path = os.path.join(category_folder, new_filename)\n",
    "        date_path = os.path.join(date_folder, new_filename)\n",
    "\n",
    "        shutil.copy(file_path, category_path)  # Store in Thermal/Visible folder\n",
    "        shutil.move(file_path, date_path)  # Move to Date-wise folder\n",
    "\n",
    "        # Append metadata to list\n",
    "        metadata_list.append({\n",
    "            \"Original FileName\": filename,\n",
    "            \"New FileName\": new_filename,\n",
    "            \"Date\": date,\n",
    "            \"Time\": time,\n",
    "            \"Latitude\": lat,\n",
    "            \"Longitude\": lon,\n",
    "            \"Category\": category,\n",
    "            \"Category Path\": category_path,\n",
    "            \"Date Path\": date_path\n",
    "        })\n",
    "\n",
    "    # Save metadata to CSV in a structured format\n",
    "    metadata_df = pd.DataFrame(metadata_list)\n",
    "    metadata_df.to_csv(METADATA_CSV, index=False)\n",
    "\n",
    "    print(\"âœ… Metadata extraction and image organization successfully completed!\")\n",
    "    print(f\"ðŸ“„ Metadata saved to {METADATA_CSV}\")\n",
    "\n",
    "# Run the script\n",
    "organize_images()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7eb2bf-fb29-4859-9211-a53b0d441cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f217e5c-f2d7-4064-95dd-413579a2449f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
